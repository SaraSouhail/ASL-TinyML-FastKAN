# ğŸš€ ASL TinyML â€” FastKAN for Real-Time Sign Language Recognition

## ğŸ§© Description
This project builds a compact and optimized deep-learning pipeline to recognize 37 ASL classes (digits 0â€“9, letters aâ€“z, and space) from images, using a custom FastKAN architecture. The model is trained on a merged dataset weighted 18 go (multiple Kaggle sources), optimized with pruning + quantization, and compressed into a deployable artifact (~12 MB) suitable for TinyML devices (ESP32 / Arduino / Raspberry Pi). The repository contains the full pipeline: data fusion, preprocessing, training (weighted loss for class imbalance), evaluation and model compression.

---

## ğŸ“ Project files (root)
- `.gitignore`  
- `ASL_TinyML_FastKAN.ipynb` â€” Main notebook: data merge, EDA, preprocessing, training, evaluation, compression.  
- `requirements.txt` â€” Python dependencies.  
- `LICENSE` â€” MIT recommended.  
- `README.md` â€” This file.  
- `fastkan_quantized_pruned.pth` â€” Final compressed model (~12 MB).
- `rename_dataset.py` â€” Script to rename duplicate images when merging.
- `data_merged` â€” Folder contains all the data merged with changing name of the images ( 18 Go ).
- `data_preprocessed` â€”  Folder contains the images preprocessed  of each class ( 9 Go ).

---
## Description of the important files :

---

### ğŸ§° Data Cleaning Script â€” `rename_dataset.py`

This script ensures that all images from different ASL datasets can be merged safely without filename conflicts.  
When multiple datasets (e.g., `data 1`, `data 2`, â€¦) contain images with the same name (like `A/1.jpg`), this script automatically:
- Renames duplicates by appending an index (â†’ `1_1.jpg`, `1_2.jpg`, etc.).  
- Normalizes subfolder names to lowercase (e.g., `A â†’ a`).  
- Copies all cleaned images into a single folder named **`data_merged/`**, maintaining class structure.  

âœ… **Result:**  
A unified, clean dataset ready for preprocessing and training â€” all duplicates resolved and files consistently named.  

**before :**
data 1/
â”œâ”€â”€ A/
â”‚   â”œâ”€â”€ 1.jpg
â”‚   â”œâ”€â”€ 2.jpg
data 2/
â”œâ”€â”€ A/
â”‚   â”œâ”€â”€ 1.jpg   # duplicate filename

**After running rename_dataset.py :**
data_merged/
â””â”€â”€ a/
    â”œâ”€â”€ 1.jpg
    â”œâ”€â”€ 1_1.jpg   âœ… duplicate safely renamed
    â”œâ”€â”€ 2.jpg

---

### ğŸ“¦ Dataset â€” `data_merged/` (not uploaded)

The **merged dataset** used for training is stored locally in the folder `data_merged/`.  
It weighs approximately **18 GB**, which makes it too large to upload to GitHub.  

It contains:
- All ASL image samples from multiple public datasets (Kaggle sources).  
- A consistent structure for 37 classes (`aâ€“z`, `0â€“9`, and `space`).  
- Cleaned and renamed images ready for preprocessing.  

ğŸ“‚ *Due to size limits, the dataset is not included in this repository but can be regenerated by rerunning `rename_dataset.py` with the original datasets.*

---

### ğŸ§  Jupyter Notebook â€” `ASL_TinyML_FastKAN.ipynb`

This is the **main notebook** that drives the entire project â€” from loading the raw data to generating the final compressed FastKAN model.  
It includes every step of the pipeline:
- Loading images from the merged dataset (`data_merged/`).
- Preprocessing and normalizing all 37 ASL classes (Aâ€“Z, 0â€“9, and space).  
- Performing exploratory data analysis (EDA) and visualizing class distribution.  
- Building, training, and evaluating the **FastKAN** model.  
- Applying pruning and quantization to compress the model into a lightweight artifact (`fastkan_quantized_pruned.pth`, ~12 MB).  

ğŸ’¡ *In short, this notebook reproduces the entire TinyML workflow â€” no extra scripts are required.*

---
## âš™ï¸ Requirements & Setup :


### âš ï¸ Important Note About the Dataset

âš ï¸ **The dataset used in this project is not included in this repository.**  
It weighs around **18 GB** and contains all merged and cleaned ASL images used for training and testing.

To successfully run the notebook, you must **first prepare the dataset** as follows:

1. Download the ASL datasets (from Kaggle or your own sources).  
   Each dataset should be placed in the root directory with names like:
data 1/
data 2/
data 3/

2. Once all datasets are placed in the root folder, run the following command in your terminal to merge and clean them:
```bash
python rename_dataset.py
```
After running the script, you should have a clean and unified dataset located at `data_merged/`:
Results should be like this :
data_merged/
â”œâ”€â”€ a/
â”œâ”€â”€ b/
â”œâ”€â”€ c/
â”œâ”€â”€ ...
â”œâ”€â”€ 0/
â”œâ”€â”€ 1/
â”œâ”€â”€ ...
â””â”€â”€ space/


### âš™ï¸ Environment Requirements
Before running the notebook, make sure your environment includes:

#### ğŸ§© Python & Tools
- **Python 3.8+**  
- **Jupyter Notebook** or **JupyterLab**  
- (Optional but recommended) **CUDA-compatible GPU** for faster training

---

#### ğŸ“¦ Install Dependencies

You can install all required libraries at once using the `requirements.txt` file:

```bash
pip install -r requirements.txt
```
## ğŸ“ˆ Model Results & Performance

### ğŸ§¹ Data Preprocessing

The preprocessing pipeline ensures high-quality, balanced input data for model training.  
It includes:

1. **Data Cleaning** â€” All images are merged and renamed using `rename_dataset.py` to remove filename conflicts.  
2. **Resizing & Normalization** â€” Each image is resized (e.g., 64Ã—64) and pixel values normalized to `[0, 1]`.  
3. **Label Encoding** â€” Converts class labels (Aâ€“Z, 0â€“9, and space) into numerical form.  
4. **Data Augmentation** â€” Adds variations (flip, rotation, brightness) to improve generalization.  
5. **Dataset Split** â€”  
   - **80%** Training  
   - **10%** Validation  
   - **10%** Testing  

---

### âš™ï¸ Model Training

The model is based on a **FastKAN (Fast Kolmogorovâ€“Arnold Network)** architecture â€” a compact and efficient design optimized for **TinyML** applications.

**Training configuration:**
- Optimizer: **Adam**
- Loss Function: **Weighted Cross-Entropy**
- Epochs: **50**
- Batch Size: **64**
- Learning Rate: **1e-3**
- Device: GPU (optional, CUDA-compatible)

After training, the model undergoes:
- **Pruning** to remove redundant parameters.  
- **Quantization** to convert weights from `float32` â†’ `int8`, reducing the size from ~85 MB â†’ **~12 MB**.

---

### ğŸ§ª Evaluation Metrics

After training and compression, the FastKAN model achieved the following performance:

| Metric | Score |
|--------|--------|
| **Overall Accuracy** | **73%** |
| **Macro Avg Precision** | **0.79** |
| **Macro Avg Recall** | **0.79** |
| **Macro Avg F1-Score** | **0.78** |
| **Weighted Avg F1-Score** | **0.73** |
| **Total Test Samples** | **71,236** |
| **Model Size (quantized)** | **~12 MB** |

---

### ğŸ§© Class-Level Highlights

| Class | Precision | Recall | F1-Score | Support |
|--------|------------|---------|-----------|----------|
| **0** | 0.75 | 0.99 | 0.85 | 479 |
| **1** | 0.97 | 0.99 | 0.98 | 308 |
| **2** | 0.62 | 0.93 | 0.75 | 319 |
| **3** | 0.97 | 0.98 | 0.97 | 333 |
| **4** | 0.96 | 0.98 | 0.97 | 460 |
| **5** | 0.82 | 0.72 | 0.77 | 478 |
| **6** | 0.72 | 0.98 | 0.83 | 467 |
| **7** | 0.99 | 0.97 | 0.98 | 511 |
| **8** | 0.93 | 0.99 | 0.96 | 487 |
| **9** | 1.00 | 0.99 | 0.99 | 483 |
| **a** | 0.60 | 0.79 | 0.68 | 2746 |
| **b** | 0.90 | 0.51 | 0.65 | 2733 |
| **c** | 0.72 | 0.76 | 0.74 | 2852 |
| **d** | 0.78 | 0.70 | 0.74 | 2677 |
| **e** | 0.45 | 0.79 | 0.57 | 2413 |
| **f** | 0.71 | 0.77 | 0.74 | 2725 |
| **g** | 0.90 | 0.52 | 0.66 | 2718 |
| **h** | 0.88 | 0.64 | 0.74 | 2763 |
| **i** | 0.76 | 0.76 | 0.76 | 2929 |
| **j** | 0.91 | 0.77 | 0.83 | 2379 |
| **k** | 0.70 | 0.76 | 0.73 | 2608 |
| **l** | 0.73 | 0.86 | 0.79 | 2773 |

*(Other ASL letters follow a similar trend â€” showing robust performance across most classes.)*

---

### ğŸª¶ Model Compression Results

| Step | Size | Reduction |
|------|------|-----------|
| Original Model | 85 MB | â€” |
| After Pruning | 35 MB | â†“ 59% |
| After Quantization | **12 MB** | â†“ 86% total |

âœ… The final model maintains competitive accuracy while being extremely lightweight â€” making it deployable on **ESP32**, **Arduino**, and **Raspberry Pi** devices.

---

### âš¡ Real-Time Compatibility

The final quantized model supports:
- **TensorFlow Lite (TFLite)** conversion for microcontrollers  
- **ONNX export** for embedded systems (Jetson Nano, Raspberry Pi, etc.)  

ğŸ’¡ *This performance proves the FastKAN model can deliver accurate real-time ASL recognition even under TinyML constraints.*
