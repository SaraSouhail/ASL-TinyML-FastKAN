# 🚀 ASL TinyML — FastKAN for Real-Time Sign Language Recognition

## 🧩 Description
This project builds a compact and optimized deep-learning pipeline to recognize 37 ASL classes (digits 0–9, letters a–z, and space) from images, using a custom FastKAN architecture. The model is trained on a merged dataset weighted 18 go (multiple Kaggle sources), optimized with pruning + quantization, and compressed into a deployable artifact (~12 MB) suitable for TinyML devices (ESP32 / Arduino / Raspberry Pi). The repository contains the full pipeline: data fusion, preprocessing, training (weighted loss for class imbalance), evaluation and model compression.

---

## 📁 Project files (root)
- `.gitignore`  
- `ASL_TinyML_FastKAN.ipynb` — Main notebook: data merge, EDA, preprocessing, training, evaluation, compression.  
- `requirements.txt` — Python dependencies.  
- `LICENSE` — MIT recommended.  
- `README.md` — This file.  
- `fastkan_quantized_pruned.pth` — Final compressed model (~12 MB).
- `rename_dataset.py` — Script to rename duplicate images when merging.
- `data_merged` — Folder contains all the data merged with changing name of the images ( 18 Go ).
- `data_preprocessed` —  Folder contains the images preprocessed  of each class ( 9 Go ).

---
## Description of the important files :

---

### 🧰 Data Cleaning Script — `rename_dataset.py`

This script ensures that all images from different ASL datasets can be merged safely without filename conflicts.  
When multiple datasets (e.g., `data 1`, `data 2`, …) contain images with the same name (like `A/1.jpg`), this script automatically:
- Renames duplicates by appending an index (→ `1_1.jpg`, `1_2.jpg`, etc.).  
- Normalizes subfolder names to lowercase (e.g., `A → a`).  
- Copies all cleaned images into a single folder named **`data_merged/`**, maintaining class structure.  

✅ **Result:**  
A unified, clean dataset ready for preprocessing and training — all duplicates resolved and files consistently named.  

**before :**
data 1/
├── A/
│   ├── 1.jpg
│   ├── 2.jpg
data 2/
├── A/
│   ├── 1.jpg   # duplicate filename

**After running rename_dataset.py :**
data_merged/
└── a/
    ├── 1.jpg
    ├── 1_1.jpg   ✅ duplicate safely renamed
    ├── 2.jpg

---

### 📦 Dataset — `data_merged/` (not uploaded)

The **merged dataset** used for training is stored locally in the folder `data_merged/`.  
It weighs approximately **18 GB**, which makes it too large to upload to GitHub.  

It contains:
- All ASL image samples from multiple public datasets (Kaggle sources).  
- A consistent structure for 37 classes (`a–z`, `0–9`, and `space`).  
- Cleaned and renamed images ready for preprocessing.  

📂 *Due to size limits, the dataset is not included in this repository but can be regenerated by rerunning `rename_dataset.py` with the original datasets.*

---

### 🧠 Jupyter Notebook — `ASL_TinyML_FastKAN.ipynb`

This is the **main notebook** that drives the entire project — from loading the raw data to generating the final compressed FastKAN model.  
It includes every step of the pipeline:
- Loading images from the merged dataset (`data_merged/`).
- Preprocessing and normalizing all 37 ASL classes (A–Z, 0–9, and space).  
- Performing exploratory data analysis (EDA) and visualizing class distribution.  
- Building, training, and evaluating the **FastKAN** model.  
- Applying pruning and quantization to compress the model into a lightweight artifact (`fastkan_quantized_pruned.pth`, ~12 MB).  

💡 *In short, this notebook reproduces the entire TinyML workflow — no extra scripts are required.*

---
## ⚙️ Requirements & Setup :


### ⚠️ Important Note About the Dataset

⚠️ **The dataset used in this project is not included in this repository.**  
It weighs around **18 GB** and contains all merged and cleaned ASL images used for training and testing.

To successfully run the notebook, you must **first prepare the dataset** as follows:

1. Download the ASL datasets (from Kaggle or your own sources).  
   Each dataset should be placed in the root directory with names like:
data 1/
data 2/
data 3/

2. Once all datasets are placed in the root folder, run the following command in your terminal to merge and clean them:
```bash
python rename_dataset.py
```
After running the script, you should have a clean and unified dataset located at `data_merged/`:
Results should be like this :
data_merged/
├── a/
├── b/
├── c/
├── ...
├── 0/
├── 1/
├── ...
└── space/


### ⚙️ Environment Requirements
Before running the notebook, make sure your environment includes:

#### 🧩 Python & Tools
- **Python 3.8+**  
- **Jupyter Notebook** or **JupyterLab**  
- (Optional but recommended) **CUDA-compatible GPU** for faster training

---

#### 📦 Install Dependencies

You can install all required libraries at once using the `requirements.txt` file:

```bash
pip install -r requirements.txt
```
## 📈 Model Results & Performance

### 🧹 Data Preprocessing

The preprocessing pipeline ensures high-quality, balanced input data for model training.  
It includes:

1. **Data Cleaning** — All images are merged and renamed using `rename_dataset.py` to remove filename conflicts.  
2. **Resizing & Normalization** — Each image is resized (e.g., 64×64) and pixel values normalized to `[0, 1]`.  
3. **Label Encoding** — Converts class labels (A–Z, 0–9, and space) into numerical form.  
4. **Data Augmentation** — Adds variations (flip, rotation, brightness) to improve generalization.  
5. **Dataset Split** —  
   - **80%** Training  
   - **10%** Validation  
   - **10%** Testing  

---

### ⚙️ Model Training

The model is based on a **FastKAN (Fast Kolmogorov–Arnold Network)** architecture — a compact and efficient design optimized for **TinyML** applications.

**Training configuration:**
- Optimizer: **Adam**
- Loss Function: **Weighted Cross-Entropy**
- Epochs: **50**
- Batch Size: **64**
- Learning Rate: **1e-3**
- Device: GPU (optional, CUDA-compatible)

After training, the model undergoes:
- **Pruning** to remove redundant parameters.  
- **Quantization** to convert weights from `float32` → `int8`, reducing the size from ~85 MB → **~12 MB**.

---

### 🧪 Evaluation Metrics

After training and compression, the FastKAN model achieved the following performance:

| Metric | Score |
|--------|--------|
| **Overall Accuracy** | **73%** |
| **Macro Avg Precision** | **0.79** |
| **Macro Avg Recall** | **0.79** |
| **Macro Avg F1-Score** | **0.78** |
| **Weighted Avg F1-Score** | **0.73** |
| **Total Test Samples** | **71,236** |
| **Model Size (quantized)** | **~12 MB** |

---

### 🧩 Class-Level Highlights

| Class | Precision | Recall | F1-Score | Support |
|--------|------------|---------|-----------|----------|
| **0** | 0.75 | 0.99 | 0.85 | 479 |
| **1** | 0.97 | 0.99 | 0.98 | 308 |
| **2** | 0.62 | 0.93 | 0.75 | 319 |
| **3** | 0.97 | 0.98 | 0.97 | 333 |
| **4** | 0.96 | 0.98 | 0.97 | 460 |
| **5** | 0.82 | 0.72 | 0.77 | 478 |
| **6** | 0.72 | 0.98 | 0.83 | 467 |
| **7** | 0.99 | 0.97 | 0.98 | 511 |
| **8** | 0.93 | 0.99 | 0.96 | 487 |
| **9** | 1.00 | 0.99 | 0.99 | 483 |
| **a** | 0.60 | 0.79 | 0.68 | 2746 |
| **b** | 0.90 | 0.51 | 0.65 | 2733 |
| **c** | 0.72 | 0.76 | 0.74 | 2852 |
| **d** | 0.78 | 0.70 | 0.74 | 2677 |
| **e** | 0.45 | 0.79 | 0.57 | 2413 |
| **f** | 0.71 | 0.77 | 0.74 | 2725 |
| **g** | 0.90 | 0.52 | 0.66 | 2718 |
| **h** | 0.88 | 0.64 | 0.74 | 2763 |
| **i** | 0.76 | 0.76 | 0.76 | 2929 |
| **j** | 0.91 | 0.77 | 0.83 | 2379 |
| **k** | 0.70 | 0.76 | 0.73 | 2608 |
| **l** | 0.73 | 0.86 | 0.79 | 2773 |

*(Other ASL letters follow a similar trend — showing robust performance across most classes.)*

---

### 🪶 Model Compression Results

| Step | Size | Reduction |
|------|------|-----------|
| Original Model | 85 MB | — |
| After Pruning | 35 MB | ↓ 59% |
| After Quantization | **12 MB** | ↓ 86% total |

✅ The final model maintains competitive accuracy while being extremely lightweight — making it deployable on **ESP32**, **Arduino**, and **Raspberry Pi** devices.

---

### ⚡ Real-Time Compatibility

The final quantized model supports:
- **TensorFlow Lite (TFLite)** conversion for microcontrollers  
- **ONNX export** for embedded systems (Jetson Nano, Raspberry Pi, etc.)  

💡 *This performance proves the FastKAN model can deliver accurate real-time ASL recognition even under TinyML constraints.*
